{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 프랑스 영화 리뷰 데이터 구축과 감정분석\n",
    "\n",
    "### By Sungwoo Stanislas Kwon (권성우)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "주제 변경 이유:\n",
    "- 형태소 분석 경험 부족으로 인한 어려움.\n",
    "- 보여주고자 했던 바를 증명하기에는 부족했던 술어들의 다양성.\n",
    "- 복잡한 분석 보다는 그런 분석에 사용 될 수 있는 새로운 데이터를 스스로 구축 해보는 것도 의미있는 일 일것 같다고 생각.\n",
    "\n",
    "새로운 주제:\n",
    "- 프랑스 텔레비전 산업 관련 사이트 allociné.fr\n",
    "- 그 중 '영화' 목록에있는 영화들의 제목, 별점, 리뷰 등등 스크랩해와 데이터셋 구축, 감정분석 실시."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "주요 태스크:\n",
    "- BeautifulSoup를 이용한 데이터 스크래핑과 데이터셋 구축, 전처리 & 간단한 수치들 시각화.\n",
    "- TF-IDF embedding을 이용해 간단한 감정 분류기 구축(로지스틱 회귀).\n",
    "- BERT?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 데이터 스크래핑과 전처리\n",
    "[allociné.fr](https://www.allocine.fr/)에서 십만개가 넘는 영화 url들을 추출하고 그 url에 접근해서 해당 영화 리뷰 (최대) 30개, 별점등을 스크래핑해와 데이터셋 구축\n",
    "- 데이터셋을 1부터10까지 만들어야 했기에 사실상 가장 복잡했던 부분.\n",
    "- 또한 처리해야하는 데이터가 상당히 많아서 코드 돌리는데도 시간이 매우 오래걸림.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allocine_df.sample(3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](project\\images\\df_example.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Polarity coding:\n",
    "- 1: positive: 4-5점\n",
    "- 0: neutral: 2점 초과 4점 미만\n",
    "- -1: negative: 0-2점"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Counts of ratings            |  Coded polarity\n",
    ":-------------------------:|:-------------------------:\n",
    "![](project\\images\\rating_counts.png)  |  ![](project\\images\\coded_polarity.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 년도별 리뷰 개수\n",
    "\n",
    "![](project\\images\\review_peryear.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 리뷰 길이 분포\n",
    "\n",
    "- 2000자 이상으로 구성되어 있는 리뷰(전체 데이터의 약 6%)는 잘라냄.\n",
    "\n",
    "![](project\\images\\review_length.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_percentage(df, previous_length):\n",
    "    new_length = len(df)\n",
    "    percentage = 100*(1-(new_length/previous_length))    \n",
    "    return new_length, percentage  \n",
    "\n",
    "# 1. 필요없는 열 삭제\n",
    "dataset_df = dataset_df.drop(columns=['rating', 'date', 'helpful', 'unhelpful'])\n",
    "\n",
    "# 2. 필요없는 행 삭제 (polarity가 neutral한 행들)\n",
    "dataset_df = dataset_df[dataset_df['polarity'] != 0]\n",
    "length, percentage = loss_percentage(dataset_df, initial_len)\n",
    "print(\"Length: {} (-{:.1f} %)\".format(length, percentage))\n",
    "\n",
    "# 3. 2000자 넘는 리뷰 삭제\n",
    "LENGTH_THRESH = 2000\n",
    "dataset_df = dataset_df[dataset_df['review'].str.len() <= LENGTH_THRESH]\n",
    "length, percentage = loss_percentage(dataset_df, length)\n",
    "print(\"Length: {} (-{:.1f} %)\".format(length, percentage))\n",
    "\n",
    "# 4. 각 영화별 리뷰 30개로 제한\n",
    "MAX_REVIEWS_PER_FILM = 30\n",
    "grouped = dataset_df.groupby('film-url')\n",
    "for ids in grouped.groups.values():\n",
    "    num_reviews = len(ids)    \n",
    "    if num_reviews > MAX_REVIEWS_PER_FILM:\n",
    "        sampling_size = num_reviews - MAX_REVIEWS_PER_FILM\n",
    "        ids_to_drop = random.sample(list(ids), sampling_size)\n",
    "        dataset_df = dataset_df.drop(ids_to_drop)\n",
    "\n",
    "length, percentage = loss_percentage(dataset_df, length)\n",
    "print(\"Length: {} (-{:.1f} %)\".format(length, percentage))\n",
    "\n",
    "length, percentage = loss_percentage(dataset_df, initial_len)\n",
    "print(\"Total loss: (-{:.1f} %)\".format(percentage))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그 밖의 전처리\n",
    "\n",
    "- negative한 리뷰를 -1에서 0으로 코딩\n",
    "- 텍스트 클리닝 (공백, 줄 바꾸기 제거 등.)\n",
    "- 비어있는 리뷰 삭제\n",
    "- 긍정 & 부정 리뷰 개수 맞추기\n",
    "\n",
    "![](project\\images\\data_freq.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. TF-IDF를 이용한 감정분류 머신러닝 모델 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PICKLE_PATH = \"allocine_dataset.pickle\"\n",
    "\n",
    "with open(PICKLE_PATH, 'rb') as reader:\n",
    "    data = pickle.load(reader)\n",
    "\n",
    "X_train, y_train = np.array(data[\"train_set\"]['review']), np.array(data[\"train_set\"]['polarity'])\n",
    "X_val, y_val = np.array(data[\"val_set\"]['review']), np.array(data[\"val_set\"]['polarity'])\n",
    "X_test, y_test = np.array(data[\"test_set\"]['review']), np.array(data[\"test_set\"]['polarity'])\n",
    "class_names = data['class_names']\n",
    "\n",
    "print(\"LEN TRAIN: \"+ str(len(X_train)))\n",
    "print(\"LEN VAL: \"+ str(len(X_val)))\n",
    "print(\"LEN TEST: \"+ str(len(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "tfidf_clf = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('clf', LogisticRegression(n_jobs=-1, verbose=1)),\n",
    "])\n",
    "\n",
    "tfidf_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "# Predicting training dataset\n",
    "y_pred = tfidf_clf.predict(X_train)\n",
    "print(\"Training Accuracy:\", metrics.accuracy_score(y_train, y_pred))\n",
    "\n",
    "# Predicting with a test dataset\n",
    "\n",
    "y_pred = tfidf_clf.predict(X_val)\n",
    "print(\"Validation Accuracy:\", metrics.accuracy_score(y_val, y_pred))\n",
    "print()\n",
    "print(metrics.classification_report(y_val, y_pred, target_names=class_names.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "# Predicting training dataset\n",
    "y_pred = tfidf_clf.predict(X_train)\n",
    "print(\"Training Accuracy:\", metrics.accuracy_score(y_train, y_pred))\n",
    "\n",
    "# Predicting with a test dataset\n",
    "\n",
    "y_pred = tfidf_clf.predict(X_val)\n",
    "print(\"Validation Accuracy:\", metrics.accuracy_score(y_val, y_pred))\n",
    "print()\n",
    "print(metrics.classification_report(y_val, y_pred, target_names=class_names.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](project\\images\\learning_curve.png) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "false_pos = X_val[(y_val == 0) & (y_pred == 1)]\n",
    "false_neg = X_val[(y_val == 1) & (y_pred == 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "custom_stopwords = set([\"de\", \"se\", \"à\", \"en\", \"par\", \"le\", \"la\", \"les\", \"aux\", \"et\", \"est\", \"ses\", \"au\", \"du\", \"quelques\", \"faire\", \n",
    "                        \"ce\", \"cette\", \"si\", \"dans\", \"un\", \"des\", \"film\",\"films\",\"pas\",\"une\",\"que\",\"mai\", \"son\", \"qui\", \"avec\",\"il\",\n",
    "                        \"elle\",\"ils\",\"pour\",\"c'est\",\"sont\",\"sur\",\"je\",\"qu'il\", \"qu'elle\", \"sa\", \"tout\", \"même\",'fait','ne','plu','san',\n",
    "                        'plus','voir','d','mais','très','bien','bon','ou','sans','comme','peu','nous','y','ça','l','scène',\"n'est\",\"d'un\",\n",
    "                        \"acteur\",\"personnage\",'deux','lui','leur','entre','vous','vou',\"d'une\",\"aussi\",\"ces\",\"où\",\"scénario\",\"acteurs\",\"dont\",\n",
    "                        \"quand\",'cela','ceci','personnages','être','peut','moins','rôles','qu','histoire',\"j'ai\",'car',\"qu'on\",'reste','toute',\n",
    "                        'tous','là','vraiment','été','autre'])\n",
    "\n",
    "# Add default English stopwords from WordCloud\n",
    "stopwords = set(STOPWORDS)\n",
    "stopwords.update(custom_stopwords)\n",
    "\n",
    "# Word cloud for false_pos\n",
    "false_pos_text = ''.join(false_pos)\n",
    "wordcloud_false_pos = WordCloud(width=800, height=400, max_words=200, background_color='white', stopwords=stopwords).generate(false_pos_text)\n",
    "\n",
    "# Plot word cloud for false_pos\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.imshow(wordcloud_false_pos, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.title('Word Cloud for False Positives')\n",
    "plt.show()\n",
    "\n",
    "# Word cloud for false_neg\n",
    "false_neg_text = ''.join(false_neg)\n",
    "wordcloud_false_neg = WordCloud(width=800, height=400, max_words=200, background_color='white', stopwords=stopwords).generate(false_neg_text)\n",
    "\n",
    "# Plot word cloud for false_neg\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.imshow(wordcloud_false_neg, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.title('Word Cloud for False Negatives')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
